import pandas as pd
from sklearn.model_selection import train_test_split

# Define the paths to the datasets
dataset_2_path = "/mnt/data/table_1fdb7992-7c9a-4fb3-9504-f8cce7e0154d.csv"
dataset_3_path = "/mnt/data/table_ebec359a-f771-4180-8957-42d8334d72e9.csv"

# Load the datasets
dataset_2 = pd.read_csv(dataset_2_path)
dataset_3 = pd.read_csv(dataset_3_path)

# Clean and standardize 'Smoker_Type' in both datasets
dataset_3['Smoker_Type'] = dataset_3['Smoker_Type'].str.replace('_', ' ')

# Merge the datasets
merged_data = pd.merge(dataset_3, dataset_2, on="Smoker_Type", how="left")

# Handle missing values
merged_data.fillna(merged_data.median(), inplace=True)

# Feature selection
features = merged_data[['Age', 'Smoker_Type', 'Non-natural cause', 'Respiratory disease', 'Cardiovascular disease', 'Other form of cancer', 'Lung cancer']]
target = merged_data['Proportion']  # Adjust this target based on your dataset's target feature

# Encode categorical data
features = pd.get_dummies(features)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)

# Verify the splitting
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)
